{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Edges directional tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"/Users/serbe/Documents/GitHub/new_arena/\")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from scipy import stats\n",
    "from os.path import split\n",
    "import pylab\n",
    "import data_analysis.tools as tools\n",
    "import data_analysis.calcium_analysis as calcium_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading several ROIs at once:\n",
    "\n",
    "There are several tools for in the *data_analysis.calcium_analysis* package for the analysis of several ROI at once. It is assumed that all these ROI come from the same imaging session (or from the same *.tiff file) which means that their names start all in the same way and they share one *.sti2-file which also has this name.\n",
    "\n",
    "The variable *path* defines the common path of all ROIs that we want to load (and at the same time the name of the corresponding *.sti2, and *.png files belonging to that imaging session)\n",
    "\n",
    "The function *get_all_experiment_data* takes that path and outputs a list with *ExperimentData*-object, a numpy-array with the mean calcium signal and a numpy-array with the ROI selections as binary masks in the same size as the imaging frame.\n",
    "\n",
    "#### Baseline definition:\n",
    "\n",
    "* The function *get_all_experiment_data* takes again an optional argument *baseline_samples* that defines which samples to take as baseline for each ROI.\n",
    "* The function *apply_dff_window_algorithm* can be applied seperately to each element of the data list. \n",
    "    * IMPORTANT : This should be done only once, since it changes the *ExperimentData* objects in the cache. Either you take care that this function is executed only once, or you write it into the same cell (in a Python Notebook) where you also load the data from the *.bin-files, so that each time you execute this cell the old data in the cache is overwritten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: No *.png files existing or path wrong\n"
     ]
    }
   ],
   "source": [
    "path = \"roi_selected//T4T5_ctrl_bars_2016-11-16_17.01\"\n",
    "\n",
    "name_of_file = split(path)[-1]\n",
    "\n",
    "\n",
    "#list_E, mean_signal, roi_masks = calcium_analysis.get_all_experiment_data(path, baseline_samples=np.array([0,1,2,3,4]))\n",
    "\n",
    "list_E, mean_signal, roi_masks = calcium_analysis.get_all_experiment_data(path)\n",
    "for E in list_E:\n",
    "    calcium_analysis.apply_dff_window_algorithm(E, plot = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: evaluating several ROIs at once (tuning curve)\n",
    "\n",
    "Now you have a list called *list_E* which contains all pre-processed data. You can access single ROIs via list_E[i], where i is some integer within the range, and analyze them as you want.\n",
    "\n",
    "For doing the same analysis for all ROIs, it makes sense to define functions that you can repeat easily.\n",
    "\n",
    "Here, we want to do the same plot as in the single-ROI script, just for each ROI, and show the ROI selection alongside, to decide then which ROIs we want to select for further analysis.\n",
    "\n",
    "For that, we define a function that plots A) the single traces for each ROI, B) the tuning curve for all stimulation frequencies, C) the ROI selection in the mean signal.\n",
    "\n",
    "We want this function to output the individual tuning curve for this ROI, so that we later can plot a mean tuning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-cf07ed7dccd5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;31m# EXAMPLE USAGE:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m14\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m \u001b[0mwidth_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_all_width_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_E\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_signal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroi_masks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"ROI \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# define a function with all arguments that we need: the data, the mean signal, the roi selection mask, some title or name\n",
    "def make_all_width_plot(E, mean_signal, roi_mask, title = \"no title\"):\n",
    "    \n",
    "    # get all orientations that were presented\n",
    "    width = E.d_stimulus_parameters['dz [units]'].values\n",
    "    width = np.sort(width)\n",
    "    width = width[::4]\n",
    "    \n",
    "    # initialize storage array for the evaluated ata\n",
    "    width_response = np.zeros(len(width))\n",
    "\n",
    "    # PLOT1: plot the single traces for each stimulation orientation (and get the tuning curve at the same time)\n",
    "    fig = plt.figure(figsize = (10,10))\n",
    "    ax = fig.add_axes([0.1,0.1,0.4,0.9]) \n",
    "    colors = sb.color_palette('husl', len(width))\n",
    "    polarity = 0.0\n",
    "\n",
    "    # go through all orientations and extract the corresponding data\n",
    "    for i in range(len(width)):\n",
    "        offset = 3*i\n",
    "        w = width[i]\n",
    "        data, sti_data, N, params_dict, h = E.get_by_stimulus_parameters([('name', 'stimuli.default.VPassingBar'), ('intensity', 255.0), ('dz [units]', w), ('velocity [cm/sec]', 3.0)])\n",
    "\n",
    "        # get the mean value and plot a thick solid line\n",
    "        # NOTE: the \"loc\" command of a pandas.DataFrame localizes elements within the DataFrame. The first parameter \n",
    "        # refers to the y-axis (here the sample number) and the second parameter to the column name.\n",
    "        # For more information read the pandas-Documentation, forums etc...\n",
    "        plt.plot(data['time'], data.loc[:, 'mean'] + offset, color = colors[i], linewidth = 2.0)\n",
    "\n",
    "        # get the single trials and plot them with an alpha value of 0.2\n",
    "        plt.plot(data['time'], data.loc[:, '0':] + offset, color = colors[i], alpha = 0.2, linewidth = 2.0)\n",
    "        \n",
    "        # evaluate the mean response during the stimulation period\n",
    "        width_response[i] = data.set_index('time').loc[0:10, 'mean'].max()\n",
    "        \n",
    "\n",
    "    # define yticks\n",
    "    plt.yticks(np.arange(len(width)))\n",
    "    ax.set_yticklabels([0, 1] + ['' for i in range(2, len(width))], fontsize = 20.)\n",
    "    ax.set_ylabel('$\\Delta F /F$', fontsize = 20.)\n",
    "\n",
    "    # define xticks\n",
    "    plt.xlim([-5,12])\n",
    "    plt.xticks([0,10])\n",
    "    ax.set_xticklabels([0, 10], fontsize = 20.)\n",
    "    ax.set_xlabel('time [sec]', fontsize = 20.)\n",
    "    \n",
    "    # plot some title or name above it, so that we can identify the ROI\n",
    "    ax.set_title(title, fontsize = 20.)\n",
    "    \n",
    "    \n",
    "    # PLOT2: SHOW THE TUNING CURVE\n",
    "    ax = fig.add_axes([0.6,0.6,0.4,0.4]) \n",
    "    \n",
    "    # define the x-axis and plot everything on a log-scale\n",
    "    stimulus_width = width\n",
    "    plt.plot(stimulus_width, width_response, linewidth = 3.0, marker = 'o')\n",
    "    \n",
    "\n",
    "    # define the x-axis and ticks etc...\n",
    "    ax.set_xlim([0,7])\n",
    "    ax.set_xticks([0.1,0.2,0.4,0.8,1.6,3.2,6.4])\n",
    "    ax.set_xticklabels(['left','up','right','down'], fontsize = 15.)\n",
    "    ax.set_xlabel('Width', fontsize = 20.)\n",
    "    \n",
    "    maximum = np.max(width_response) + 1\n",
    "\n",
    "    # define the y-axis and ticks etc...\n",
    "    ax.set_ylim([-0,maximum])\n",
    "    ax.set_yticks([0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0])\n",
    "    ax.set_yticklabels([0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0], fontsize = 15.)\n",
    "    ax.set_ylabel('$\\Delta F/F$', fontsize = 20.)\n",
    "    \n",
    "    \n",
    "    #PLOT3: SHOW THE ROI SELECTION\n",
    "    ax = fig.add_axes([0.6,0.1,0.4,0.4])\n",
    "    # show the mean signal \n",
    "    ax.imshow(mean_signal, cmap = plt.get_cmap('Greys_r'), interpolation = 'nearest')\n",
    "    # show the roi selection as an overlay with slight transparency\n",
    "    ax.imshow(1-roi_mask, alpha = 0.3, interpolation = 'nearest')\n",
    "    ax.grid(False)\n",
    "    \n",
    "    return width_response\n",
    "    \n",
    "\n",
    "    \n",
    "# EXAMPLE USAGE:\n",
    "i = 14\n",
    "width_response = make_all_width_plot(list_E[i], mean_signal, roi_masks[:,:,i], title = \"ROI \" + str(i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define a function with all arguments that we need: the data, the mean signal, the roi selection mask, some title or name\n",
    "def make_all_width_list(E, mean_signal, roi_mask, title = \"no title\"):\n",
    "    \n",
    "    # get all orientations that were presented\n",
    "    width = E.d_stimulus_parameters['dz [units]'].values\n",
    "    width = np.sort(width)\n",
    "    width = width[::4]\n",
    "    \n",
    "    # initialize storage array for the evaluated ata\n",
    "    ON_width_response = np.zeros(len(width))\n",
    "    OFF_width_response = np.zeros(len(width))\n",
    "\n",
    "    # go through all orientations and extract the corresponding data\n",
    "    for i in range(len(width)):\n",
    "        w = width[i]\n",
    "        data, sti_data, N, params_dict, h = E.get_by_stimulus_parameters([('name', 'stimuli.default.VPassingBar'), ('bg_intensity', 0.0), ('intensity', 255.0), ('dz [units]', w), ('velocity [cm/sec]', 3.0)])\n",
    "        \n",
    "        # evaluate the mean response during the stimulation period\n",
    "        ON_width_response[i] = data.set_index('time').loc[0:20, 'mean'].max()\n",
    "        \n",
    "    for i in range(len(width)):\n",
    "        w = width[i]\n",
    "        data, sti_data, N, params_dict, h = E.get_by_stimulus_parameters([('name', 'stimuli.default.VPassingBar'), ('bg_intensity', 255.0), ('intensity', 0.0), ('dz [units]', w), ('velocity [cm/sec]', 3.0)])\n",
    "        ()\n",
    "        # evaluate the mean response during the stimulation period\n",
    "        OFF_width_response[i] = data.set_index('time').loc[0:20, 'mean'].max()\n",
    "\n",
    "    return ON_width_response, OFF_width_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing ROIs\n",
    "\n",
    "Now, we just execute that function for each element of *list_E* so that we can look at the data and choose later which ROIs we would like to keep for the final analysis.\n",
    "At the same time, we save the tuning curve for each ROI in a list called *list_tunings* so that we can work with that later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_tunings = []\n",
    "for i in range(len(list_E)):\n",
    "    ON_width_response = make_all_width_list(list_E[i], mean_signal, roi_masks[:,:,i], title = \"ROI \" + str(i))\n",
    "    list_tunings.append(ON_width_response)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating a mean tuning curve\n",
    "\n",
    "In this example, all ROIs seem to have responded nicely.\n",
    "\n",
    "However, for demonstration, we define a list with the indices of the ROIs (the elements of *list_E*) that we would like to take for further analysis. \n",
    "\n",
    "We call this list *take*.\n",
    "\n",
    "Then we just take all the elements with those indices from the list of tuning curves *list_tunings* (which we generated just in the last command) and store them in a numpy matrix with the rows corresponding to the stimulation frequencies and the columns corresponding to the ROIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "take_regions = np.array([[0,1,7,8,9],[10,11,12,13,14],[2,3,4,5,6]])\n",
    "number_of_regions = [0,1,2]\n",
    "for regions in number_of_regions:\n",
    "\n",
    "    take = take_regions[regions,:]\n",
    "\n",
    "    N = len(list_tunings[0][0]) # number of stimulation frequencies\n",
    "    M = len(take) # number of ROIs, that we take for further analysis\n",
    "    ON_mean_tuning = np.zeros((N,M))\n",
    "    OFF_mean_tuning = np.zeros((N,M))# initialize empty matrix\n",
    "\n",
    "    # put the single tunings into the matrix\n",
    "    for i in range(len(take)):\n",
    "        ON_mean_tuning[:,i] = list_tunings[take[i]][0]\n",
    "\n",
    "    for i in range(len(take)):\n",
    "        OFF_mean_tuning[:,i] = list_tunings[take[i]][1]\n",
    "\n",
    "    ON_max = np.zeros(len(take))\n",
    "    OFF_max = np.zeros(len(take))\n",
    "    maxi = np.zeros(len(take))\n",
    "\n",
    "    for i in range(len(take)):\n",
    "        ON_max[i] = ON_mean_tuning[:,i].max()\n",
    "        OFF_max[i] = OFF_mean_tuning[:,i].max()\n",
    "\n",
    "        if ON_max[i] > OFF_max[i]:\n",
    "            maxi[i] = ON_max[i]\n",
    "        else:\n",
    "            maxi[i] = OFF_max[i]\n",
    "\n",
    "    # normalization\n",
    "    for i in range(len(take)):\n",
    "        ON_mean_tuning[:,i] = ON_mean_tuning[:,i]/maxi[i]\n",
    "\n",
    "    for i in range(len(take)):\n",
    "        OFF_mean_tuning[:,i] = OFF_mean_tuning[:,i]/maxi[i]\n",
    "\n",
    "    mean_tuning = [ON_mean_tuning, OFF_mean_tuning]    \n",
    "        \n",
    "    # plot everything\n",
    "    plt.figure(figsize = (5,5))\n",
    "    ax = plt.subplot(111)\n",
    "\n",
    "    # here, we manually define the x-axis\n",
    "    width_tuning = [0.1,0.2,0.4,0.8,1.6,3.2,6.4]\n",
    "\n",
    "    # plot mean tuning as solid line\n",
    "    plt.plot(width_tuning, ON_mean_tuning.mean(1), color = 'b', linewidth = 3.0, marker = 'o')\n",
    "    plt.plot(width_tuning, OFF_mean_tuning.mean(1), color = 'k', linewidth = 3.0, marker = 'o')\n",
    "\n",
    "    ## plot single tunings with a lower alpha\n",
    "    # plt.plot(orientation_tuning, mean_tuning, color = 'b', linewidth = 3.0, alpha = 0.3)\n",
    "\n",
    "\n",
    "    # define the x-axis and ticks etc...\n",
    "    ax.set_xlim([0,7])\n",
    "    ax.set_xticks([0.1,0.2,0.4,0.8,1.6,3.2,6.4])\n",
    "    #ax.set_xticklabels(['left','up','right','down'], fontsize = 15.)\n",
    "    ax.set_xlabel('Width', fontsize = 20.)\n",
    "\n",
    "    # define the y-axis and ticks etc...\n",
    "    plt.ylim([0,1.1])\n",
    "    ax.set_yticks([0.0, 0.5, 1.0])\n",
    "    ax.set_yticklabels([0, 0.5, 1.0], fontsize = 20.)\n",
    "    ax.set_ylabel('$\\Delta F/F$', fontsize = 20.)\n",
    "    plt.legend(['ON', 'OFF'])\n",
    "    \n",
    "    \n",
    "    if regions == 0:\n",
    "        plt.title (\"Lobula Plate\", fontsize = 20.)\n",
    "        open(name_of_file + 'LP.npy','w')\n",
    "        np.save(name_of_file + 'LP.npy', mean_tuning)\n",
    "        pylab.savefig(name_of_file + 'LP.png')\n",
    "    elif regions == 1:\n",
    "        plt.title (\"Medulla\", fontsize = 20.)\n",
    "        open(name_of_file + 'ME.npy','w')\n",
    "        np.save(name_of_file + 'ME.npy', mean_tuning)\n",
    "        pylab.savefig(name_of_file + 'ME.png')\n",
    "    elif regions == 2:\n",
    "        plt.title (\"Lobula\", fontsize = 20.)\n",
    "        open(name_of_file + 'LO.npy','w')\n",
    "        np.save(name_of_file + 'LO.npy', mean_tuning)\n",
    "        pylab.savefig(name_of_file + 'LO.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "E.d_stimulus_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "take_regions = np.array([[0,1,7,8,9],[10,11,12,13,14],[2,3,4,5,6]])\n",
    "number_of_regions = [0,1,2]\n",
    "for regions in number_of_regions:\n",
    "\n",
    "    take = take_regions[regions,:]\n",
    "\n",
    "    N = len(list_tunings[0][0]) # number of stimulation frequencies\n",
    "    M = len(take) # number of ROIs, that we take for further analysis\n",
    "    ON_mean_tuning = np.zeros((N,M))\n",
    "    OFF_mean_tuning = np.zeros((N,M))# initialize empty matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ON_width_response"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
